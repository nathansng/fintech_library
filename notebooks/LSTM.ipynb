{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Implementation in TreNet\n",
    "\n",
    "### Authors: Nathan Ng, Gao Mo, Richard Tang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Implementation\n",
    "\n",
    "- LSTM model that feeds into linear layer that matches number of outputs as CNN stack\n",
    "- Takes as input stock trend durations and slopes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GPU if available for PyTorch\n",
    "if torch.cuda.is_available():\n",
    "    dev = \"cuda:0\"\n",
    "else:\n",
    "    dev = \"cpu\"\n",
    "\n",
    "device = torch.device(dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Scales data using Sklearn's MinMaxScaler\n",
    "Generalized to accept tensors \n",
    "\"\"\"\n",
    "class Scaler():\n",
    "    def __init__(self):\n",
    "        self.scaler = MinMaxScaler()\n",
    "        \n",
    "    def fit_transform(self, data):\n",
    "        # Check if data is tensor\n",
    "        if type(data) == torch.Tensor:\n",
    "            data = torch.Tensor.cpu(data).detach().numpy()\n",
    "            \n",
    "        # Check if data is dataframe \n",
    "        if type(data) == pd.DataFrame or type(data) == pd.Series:\n",
    "            data = data.values\n",
    "            \n",
    "        # Transform data \n",
    "        if len(data.shape) == 1: \n",
    "            scaled_data = self.scaler.fit_transform(data.reshape(-1, 1)).flatten()\n",
    "        else: \n",
    "            scaled_data = self.scaler.fit_transform(data)\n",
    "        \n",
    "        # Return tensor of scaled data\n",
    "        return torch.tensor(scaled_data, dtype=torch.float)\n",
    "    \n",
    "    def inverse_transform(self, data): \n",
    "        # Check if data is tensor\n",
    "        if type(data) == torch.Tensor:\n",
    "            data = torch.Tensor.cpu(data).detach().numpy()\n",
    "            \n",
    "        # Check if data is dataframe \n",
    "        if type(data) == pd.DataFrame or type(data) == pd.Series:\n",
    "            data = data.values\n",
    "        \n",
    "        inverse_data = self.scaler.inverse_transform(data)\n",
    "        \n",
    "        # Return tensor of inverse data\n",
    "        return torch.tensor(inverse_data, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Extracts m sequential data to use to predict n next data \n",
    "\"\"\"\n",
    "def extract_data(data, num_input, num_output):\n",
    "    num_rows = data.shape[0] - num_input - num_output\n",
    "    input_data = torch.zeros(num_rows, num_input)\n",
    "    output_data = torch.zeros(num_rows, num_output)\n",
    "    \n",
    "    for i in range(num_rows):\n",
    "        input_data[i] = (data[i:i+num_input])\n",
    "        output_data[i] = (data[i+num_input:i+num_input+num_output])\n",
    "    return input_data, output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Separates data into train, validation, and test sets\n",
    "props: (train, valid)\n",
    "\"\"\"\n",
    "def train_valid_test_split(X, y, props=None):\n",
    "    if not props: \n",
    "        props = (0.5, 0.25)\n",
    "    elif len(props) != 3: \n",
    "        print(\"Wrong number of parameters\")\n",
    "        return None\n",
    "    \n",
    "    train_size = int(X.shape[0] * props[0])\n",
    "    valid_size = int(X.shape[0] * props[1])\n",
    "    \n",
    "    X_train = X[:train_size].to(device)\n",
    "    y_train = y[:train_size].to(device)\n",
    "    \n",
    "    X_valid = X[train_size: (train_size + valid_size)].to(device)\n",
    "    y_valid = y[train_size: (train_size + valid_size)].to(device)\n",
    "    \n",
    "    X_test = X[(train_size + valid_size):].to(device)\n",
    "    y_test = y[(train_size + valid_size):].to(device)\n",
    "    \n",
    "    return X_train, y_train, X_valid, y_valid, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TreNet LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        # Initialize hidden dimenision and layers \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.input_dim = input_dim\n",
    "        \n",
    "        # Initialize deep learning models\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_().to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_().to(device)\n",
    "        \n",
    "        # Reshape data if needed\n",
    "        if len(x.shape) != 3: \n",
    "            x = x.reshape(x.shape[0], -1, self.input_dim)\n",
    "        \n",
    "        # Run data through model\n",
    "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TreNet LSTM Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create training loop\n",
    "\"\"\"\n",
    "def train_loop(n_epochs, X, y, model, loss_fn, optimizer, printout=False):\n",
    "    for i in range(n_epochs):\n",
    "        # Compute prediction and loss \n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # Perform backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print loss per epoch \n",
    "        if printout and i % 100 == 0: \n",
    "            print(f\"Epoch {i}:\\n--------------\")\n",
    "            print(f\"Train Loss: {np.sqrt(loss.item())}\")\n",
    "            print()\n",
    "            \n",
    "    # Print final loss after training \n",
    "    if printout:\n",
    "        print(f\"Final:\\n--------------\")\n",
    "        print(f\"Train Loss: {np.sqrt(loss.item())}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test LSTM Model on Raw Stock Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in NYSE data\n",
    "df = pd.read_csv(\"../data/raw/indexProcessed.csv\")\n",
    "NYSE_df = df[df[\"Index\"] == \"NYA\"].loc[:, \"Open\"].reset_index(drop=True)\n",
    "\n",
    "# Create subset of data \n",
    "NYSE_sub = NYSE_df[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data \n",
    "scaler = Scaler()\n",
    "sub = scaler.fit_transform(NYSE_sub).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract samples and create train test sets\n",
    "X, y = extract_data(sub, 49, 1)\n",
    "X_train, y_train, X_valid, y_valid, X_test, y_test = train_valid_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for model and training \n",
    "input_dim = 1\n",
    "hidden_dim = 32\n",
    "num_layers = 1\n",
    "output_dim = 1\n",
    "\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, loss function, and optimizer\n",
    "model = LSTM(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_layers=num_layers).to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\n",
      "--------------\n",
      "Train Loss: 0.6364822416502736\n",
      "\n",
      "Epoch 100:\n",
      "--------------\n",
      "Train Loss: 0.02417951330937207\n",
      "\n",
      "Epoch 200:\n",
      "--------------\n",
      "Train Loss: 0.02151661047603963\n",
      "\n",
      "Epoch 300:\n",
      "--------------\n",
      "Train Loss: 0.019583035897292017\n",
      "\n",
      "Epoch 400:\n",
      "--------------\n",
      "Train Loss: 0.01785338474140574\n",
      "\n",
      "Epoch 500:\n",
      "--------------\n",
      "Train Loss: 0.016985596585725727\n",
      "\n",
      "Epoch 600:\n",
      "--------------\n",
      "Train Loss: 0.01638641474644154\n",
      "\n",
      "Epoch 700:\n",
      "--------------\n",
      "Train Loss: 0.016015196785784662\n",
      "\n",
      "Epoch 800:\n",
      "--------------\n",
      "Train Loss: 0.015450069276580016\n",
      "\n",
      "Epoch 900:\n",
      "--------------\n",
      "Train Loss: 0.0153475867011586\n",
      "\n",
      "Final:\n",
      "--------------\n",
      "Train Loss: 0.01485405300856181\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "train_loop(1000, X_train, y_train, model, loss_fn, optimizer, printout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare predictions and actual values \n",
    "inverse_test_y = scaler.inverse_transform(y_test)\n",
    "\n",
    "pred_test_y = model(X_test)\n",
    "inverse_pred_test_y = scaler.inverse_transform(pred_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: tensor(4.3644)\n",
      "Predicted values: \n",
      "tensor([[605.6600],\n",
      "        [600.9100],\n",
      "        [595.4100],\n",
      "        [587.7900],\n",
      "        [583.5600],\n",
      "        [586.2100],\n",
      "        [583.7800],\n",
      "        [583.5600],\n",
      "        [584.5200],\n",
      "        [590.2300]])\n",
      "Actual values: \n",
      "tensor([[610.4211],\n",
      "        [603.4086],\n",
      "        [597.7258],\n",
      "        [592.2682],\n",
      "        [585.3920],\n",
      "        [580.5059],\n",
      "        [581.6049],\n",
      "        [581.1210],\n",
      "        [581.1942],\n",
      "        [582.2221]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Loss: \" + str(loss_fn(inverse_pred_test_y, inverse_test_y)**(1/2)))\n",
    "\n",
    "print(\"Predicted values: \\n\" + str(inverse_test_y[:10]))\n",
    "\n",
    "print(\"Actual values: \\n\" + str(inverse_pred_test_y[:10]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
